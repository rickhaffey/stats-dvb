{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21 - Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.1 \n",
    "\n",
    "### Answers\n",
    "\n",
    "* a)\n",
    "    * two-sided\n",
    "    * H0: p that prefer Diet Coke = 0.5\n",
    "    * HA: p that prefer Diet Coke <> 0.5\n",
    "    * the wording of this question is ambiguous and confusing; I think what they're really implicitly asking is \"Do students have a preference?\", _not_ \"Do students prefer diet coke over diet pepsi, or vice-versa?\"\n",
    "    * A better phrasing would have been: \"A business student conducts a taste test to see whether students show a preference for either Diet Coke or Diet Pepsi.\"\n",
    "* b)\n",
    "    * one-sided\n",
    "    * H0: p (prefer new formula) = 0.5\n",
    "    * HA: p > 0.5\n",
    "* c)\n",
    "    * one-sided\n",
    "    * H0: p (vote in favor) = 2/3\n",
    "    * HA: p > 2/3\n",
    "    * shouldn't this instead be \"p = 2/3n - 1\" and \"p > 2/3n - 1\"? does p = 2/3 => passing or not passing? (assume it passes)\n",
    "* d)\n",
    "    * two-sided\n",
    "    * H0: p (proportion of increases) = 0.5\n",
    "    * HA: p <> 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.3\n",
    "\n",
    "### Answers\n",
    "\n",
    "* Under conditions of the null hypothesis (i.e. the new treatment has the same effectiveness as the traditional ointment), we'd expect to see the results we obtained (or more extreme results) purely due to sampling variability only 4.7% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.5\n",
    "\n",
    "### Answers\n",
    "\n",
    "* He would have made the same decision at $\\alpha = 0.10$ because the expectations under that condition are _less_ limiting.  We'd need to know his results to answer whether he would have made the same decision under $\\alpha = 0.01$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.7\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) If the true proportion is 90%, we would only expect to see these (or more extreme) results 1.1% of the time due to pure sampling variability.\n",
    "* b) The size of the effect is a difference of only 0.6%.  Although this is fairly small, applied across a huge population (i.e. all children in the US?) could potentially have a large practical impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.9 \n",
    "\n",
    "### Answers\n",
    "\n",
    "* a)\n",
    "  - randomized telephone poll; may be response bias; n_success/n_failure both > 10; assume 1302 is < 10% of entire pop.\n",
    "  - [1.9%, 4.1%]\n",
    "* b) The CI indicates that it has fallen below the 5% mark, in that 5% isn't included in the interval.\n",
    "* c) H0 = p = 0.05, HA = p < 0.05 (one-sided); therefore alpha = 0.01 => 99% significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.029953917050691243\n",
      "sd: 0.004724082815914828\n",
      "ci: [ 0.01896406  0.04094378]\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "n_s = 1302\n",
    "n_x = 39\n",
    "alpha = 0.02\n",
    "\n",
    "p = n_x / n_s\n",
    "sd = math.sqrt(p * (1 - p) / n_s)\n",
    "ci = norm.ppf([alpha / 2, (1 - alpha / 2)], p, sd)\n",
    "\n",
    "print(\"p: {}\".format(p))\n",
    "print(\"sd: {}\".format(sd))\n",
    "print(\"ci: {}\".format(ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.11\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) [27.3%, 32.7%]\n",
    "* b) reject H0 - evidence supports claim that his approval rating was better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.3\n",
      "sd: 0.013662601021279464\n",
      "ci: [ 0.27322179  0.32677821]\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "n = 1125\n",
    "alpha = 0.05\n",
    "\n",
    "sd = math.sqrt(p * (1 - p) / n)\n",
    "ci = norm.ppf([alpha / 2, (1 - alpha / 2)], p, sd)\n",
    "\n",
    "print(\"p: {}\".format(p))\n",
    "print(\"sd: {}\".format(sd))\n",
    "print(\"ci: {}\".format(ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.13\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) less than 10 success/failures in sample => fails that condition\n",
    "* b) [4.8%, 25.6%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.15217391304347827\n",
      "sd: 0.052959585336062626\n",
      "ci: [ 0.04837503  0.25597279]\n"
     ]
    }
   ],
   "source": [
    "n_s = 42\n",
    "n_x = 5\n",
    "\n",
    "# Agresti-Coull \"plus-four\"\n",
    "p_tilde = (n_x + 2) / (n_s + 4)\n",
    "p = p_tilde  # use p_tilde for p in follow on calcs\n",
    "n = n_s + 4\n",
    "\n",
    "sd = math.sqrt(p * (1 - p) / n)\n",
    "ci = norm.ppf([alpha / 2, (1 - alpha / 2)], p, sd)\n",
    "\n",
    "print(\"p: {}\".format(p))\n",
    "print(\"sd: {}\".format(sd))\n",
    "print(\"ci: {}\".format(ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.15\n",
    "\n",
    "### Answers\n",
    "\n",
    "* H0: applicant will repay the loand\n",
    "* HA: applicant will not repay the loan (score below threshold)\n",
    "\n",
    "* a) Type II\n",
    "* b) Type I\n",
    "* c) higher alpha; the critical value is moved closer to the mean\n",
    "  NOTE: answer key has the opposite answer, which is counter-intuitive to me;  if we lower the threshold, we're increasing the area under the curve (to the right of the threshold) in which our z score can fall so that it leads us to reject the null hypothesis; this area corresponds to the alpha value (i.e. at alpha = 0.01 this area will be smaller than at alpha = 0.05, etc.); so by moving the threshold down (to the left) we increase the alpha value, not decrease it\n",
    "* d) lower chance of Type I, greater chance of Type II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.17\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) the probability of correctly denying a loan to someone who would not repay the loan\n",
    "* b) increase the cutoff point\n",
    "* c) that increase the chance of a Type II error (false negative - rejecting a candidate that would have repayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.19\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) H0: p = low value; HA: p > low value\n",
    "* b) There is no real increase, but they decide to continue the tax breaks\n",
    "* c) There is a real increase, but the decide to discontinue the tax breaks\n",
    "* d) \n",
    "  - Type I: city is harmed by applying tax revenues towards a program that isn't really working;\n",
    "  - Type II: first-time buyers are harmed by not getting a benefit that appears to actually help\n",
    "* e) The probability of identifying a real increase when it's present  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.21\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) shop is \"honest\", but they determine the shop is \"cheating\"\n",
    "* b) shop is \"cheating\", but they determine the shop is \"honest\"\n",
    "* c) Type I\n",
    "* d) Type II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.23\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) the probability that they will identify the shop as cheating (under the condition that it actually is cheating)\n",
    "* b) 40 cars - power increases with sample size\n",
    "* c) 10% - higher alpha leads to greater chance of rejecting H0\n",
    "* d) a lot - power increases with increase in effect size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.25\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) one-tailed: the implication is that a lower proportion of minorities are being hired than actually applied\n",
    "* b) Type I: hiring is fair, but test determines that it's not\n",
    "* c) Type II: hiring is unfair, but test determines that it's fair\n",
    "* d) The probability of identifying unfair hiring when it's present\n",
    "* e) Power will increase\n",
    "* f) Lower power with a lower sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.27\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) one-tailed: interested in whether the software causes a decrease in drop-out rate\n",
    "* b) H0: p = 0.13, HA: p < 0.13\n",
    "* c) professor determines the software helped, even though it doesn't\n",
    "* d) professor determines the software didn't help, even though it does\n",
    "* e) the probability that the professor determines that the software helps when it actually does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.29\n",
    "\n",
    "### Answers\n",
    "\n",
    "* a) yes - the sample shows a drop-out rate of 5.4%, with a 95% CI of 2.3% to 8.5%\n",
    "* b) if the software _didn't_ actually help, we would expect to see these (or more extreme) results due to sampling variability < 0.07% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.054187192118226604\n",
      "sd: 0.01588923177336244\n",
      "ci: [ 0.02304487  0.08532951]\n"
     ]
    }
   ],
   "source": [
    "p_0 = 0.13\n",
    "n_s = 203\n",
    "n_x = 11\n",
    "alpha = 0.05\n",
    "\n",
    "p = n_x / n_s\n",
    "sd = math.sqrt(p * (1 - p) / n_s)\n",
    "ci = norm.ppf([alpha / 2, (1 - alpha / 2)], p, sd)\n",
    "\n",
    "print(\"p: {}\".format(p))\n",
    "print(\"sd: {}\".format(sd))\n",
    "print(\"ci: {}\".format(ci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: -3.2118799061285754\n",
      "pValue: 0.0006593474382024779\n"
     ]
    }
   ],
   "source": [
    "sd2 = math.sqrt(p_0 * (1 - p_0) / n_s)\n",
    "z = (p - p_0) / sd2\n",
    "print(\"z: {}\".format(z))\n",
    "pValue = norm.cdf(p, p_0, sd2)\n",
    "pValue\n",
    "print(\"pValue: {}\".format(pValue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "### Answers\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "### Answers\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "### Answers\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "### Answers\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
